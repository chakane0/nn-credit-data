{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.neighbors import KNeighborsClassifier     #KNN\n",
    "from sklearn.linear_model import LogisticRegression    #Logistic Regression\n",
    "from sklearn.tree import DecisionTreeClassifier        #Decision Tree\n",
    "from sklearn.ensemble import RandomForestClassifier    #Random Forest\n",
    "from sklearn.neural_network import MLPClassifier       #Neural Network\n",
    "from sklearn.svm import SVC                            #SVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import tree\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "#import graphviz\n",
    "import itertools\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "We'll train, test and validate a neural network with our labeled credit data (which we add in features names for). The only thing we know about this data is that theres 999 rows and 27 columns (columns are labeled). We also assume that we can place as many neurons in the hidden layer as you like. \n",
    "\n",
    "# Introduction\n",
    "Artificial neural networks are the software implementation of the neuronal structure of our brain. the brain has neurons which can change their output state depending on the strength of their electrical or chemical input. A neural network is a massive interconnected network of neurons. Here is a simple video explaining what a <a href=\"https://www.youtube.com/watch?v=6qS83wD29PY\">neuron</a> is.\n",
    "\n",
    "We learn by repeatedly activating certain neural connections over others, this reinforces those connections and makes them more likely to preduce a desired outcome given a specified input. This learning involves feedback. By having desired outcomes, the neural connections cause that specific outcome to be more likely. Our networks will attempt to simplify and mimic brain behavior. We can train these networks in a supervised or unsupervised manner. \n",
    "\n",
    "The most basic neural network is a perceptron<br>\n",
    "<img src=\"perceptron.png\" width=\"600\" height=\"300\"></img><br> This is An algorithm for supervised learning on binary classifiers. Recall, a supervised learning algorithm is the task of learning a function that maps inputs to ourputs based on past input/outpur pairs. A perceptron is a classification algorithm that makes predictions to be used on a linear predictor function combining a set of weights w/ a feature vector. It learns a binary classifier called a threshold function which maps its input (x - a vector) to an output value (f(x) - a single binary value).\n",
    "\n",
    "# Neural Networks\n",
    "Theres many different algorithms for machine learning however the 3 main ones we usually see: Artifical neural network, Convolutional Neural Network, and Recurrent Neural Network. <b>In this example we will be using an Artifical neural network</b>. \n",
    "\n",
    "# Artificial Neural Network(ANN)\n",
    "This type of network can been seen as a group of multiple perceptrons(neurons) at each layer. We can also cateogrize this as a <a href=\"https://en.wikipedia.org/wiki/Feedforward_neural_network\">feed forward network</a>.<br>\n",
    "<img src=\"ann-diagram.png\" width=\"450\" height=\"300\"><img/><br>\n",
    "ANNs are able to learn just about any nonlinear function; people also call them Universal Function Approximators. They have the capacity to learn weights that map any input to the output. One of the key features about this algorithm is we implement an activation function which introduces nonlinear properties to the network. We consider that our output is the activation of a weighted sum on inputs<br>\n",
    "<img src=\"perceptron-g.gif\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rp/8y6kqydx4gz7_qbqgv893ccm0000gn/T/ipykernel_1055/172650798.py:14: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  credit_df.target_names= ['Good', 'Bad']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc for training data: 0.583\n",
      "acc for test data: 0.610\n"
     ]
    }
   ],
   "source": [
    "# turn our data to a dataframe\n",
    "credit_df = pd.read_csv( \"german-credit-card.txt\", delim_whitespace = True, header = None)\n",
    "\n",
    "# add column names to our data\n",
    "columns = ['checkin_acc', 'duration', 'credit_history', 'purpose', 'amount',\n",
    "           'saving_acc', 'present_emp_since', 'inst_rate', 'personal_status',\n",
    "           'other_debtors', 'residing_since', 'property', 'age',\n",
    "           'inst_plans', 'housing', 'num_credits',\n",
    "           'job', 'dependents', 'telephone', 'foreign_worker', 'status']\n",
    "           \n",
    "credit_df.columns = columns\n",
    "\n",
    "# select our tatger name (i.e good credit, bad credit)\n",
    "credit_df.target_names= ['Good', 'Bad']\n",
    "\n",
    "# # look at our data frame\n",
    "# credit_df\n",
    "\n",
    "X_features = list( credit_df.columns )\n",
    "X_features.remove( 'status' )\n",
    "\n",
    "# create new DF with values\n",
    "credit_df_complete = pd.get_dummies( credit_df[X_features], drop_first = True )\n",
    "\n",
    "Y = credit_df.status - 1  # the staus we set corresponds to a 1 or 2\n",
    "X = credit_df_complete   # pandas dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state = 42)\n",
    "\n",
    "# multi-layer perceptron classifier\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print('acc for training data: {:.3f}'.format(mlp.score(X_train, y_train)))\n",
    "print('acc for test data: {:.3f}'.format(mlp.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLEASE ADD A FEW LINES CODE AS FOLLOWS TO IMPROVE THE MODEL, For example, you need to do data normalization, data standardization, and other data mining models.   IF YOU DO NOT HAVE CODE EXPERIENCE, PLEASE DISCUSS SEVERAL APPROACH TO MAKE IMPROVEMENT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize data then use MLPClassifier on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc for training data: 1.000\n",
      "acc for test data: 0.790\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>amount</th>\n",
       "      <th>inst_rate</th>\n",
       "      <th>residing_since</th>\n",
       "      <th>age</th>\n",
       "      <th>num_credits</th>\n",
       "      <th>dependents</th>\n",
       "      <th>checkin_acc_A12</th>\n",
       "      <th>checkin_acc_A13</th>\n",
       "      <th>checkin_acc_A14</th>\n",
       "      <th>...</th>\n",
       "      <th>property_A124</th>\n",
       "      <th>inst_plans_A142</th>\n",
       "      <th>inst_plans_A143</th>\n",
       "      <th>housing_A152</th>\n",
       "      <th>housing_A153</th>\n",
       "      <th>job_A172</th>\n",
       "      <th>job_A173</th>\n",
       "      <th>job_A174</th>\n",
       "      <th>telephone_A192</th>\n",
       "      <th>foreign_worker_A202</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.050567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.313690</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.101574</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.419941</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.254209</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.081765</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.198470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.030483</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.087763</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.238032</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     duration    amount  inst_rate  residing_since       age  num_credits  \\\n",
       "0    0.029412  0.050567   1.000000        1.000000  0.857143     0.333333   \n",
       "1    0.647059  0.313690   0.333333        0.333333  0.053571     0.000000   \n",
       "2    0.117647  0.101574   0.333333        0.666667  0.535714     0.000000   \n",
       "3    0.558824  0.419941   0.333333        1.000000  0.464286     0.000000   \n",
       "4    0.294118  0.254209   0.666667        1.000000  0.607143     0.333333   \n",
       "..        ...       ...        ...             ...       ...          ...   \n",
       "995  0.117647  0.081765   0.666667        1.000000  0.214286     0.000000   \n",
       "996  0.382353  0.198470   1.000000        1.000000  0.375000     0.000000   \n",
       "997  0.117647  0.030483   1.000000        1.000000  0.339286     0.000000   \n",
       "998  0.602941  0.087763   1.000000        1.000000  0.071429     0.000000   \n",
       "999  0.602941  0.238032   0.666667        1.000000  0.142857     0.000000   \n",
       "\n",
       "     dependents  checkin_acc_A12  checkin_acc_A13  checkin_acc_A14  ...  \\\n",
       "0           0.0              0.0              0.0              0.0  ...   \n",
       "1           0.0              1.0              0.0              0.0  ...   \n",
       "2           1.0              0.0              0.0              1.0  ...   \n",
       "3           1.0              0.0              0.0              0.0  ...   \n",
       "4           1.0              0.0              0.0              0.0  ...   \n",
       "..          ...              ...              ...              ...  ...   \n",
       "995         0.0              0.0              0.0              1.0  ...   \n",
       "996         0.0              0.0              0.0              0.0  ...   \n",
       "997         0.0              0.0              0.0              1.0  ...   \n",
       "998         0.0              0.0              0.0              0.0  ...   \n",
       "999         0.0              1.0              0.0              0.0  ...   \n",
       "\n",
       "     property_A124  inst_plans_A142  inst_plans_A143  housing_A152  \\\n",
       "0              0.0              0.0              1.0           1.0   \n",
       "1              0.0              0.0              1.0           1.0   \n",
       "2              0.0              0.0              1.0           1.0   \n",
       "3              0.0              0.0              1.0           0.0   \n",
       "4              1.0              0.0              1.0           0.0   \n",
       "..             ...              ...              ...           ...   \n",
       "995            0.0              0.0              1.0           1.0   \n",
       "996            0.0              0.0              1.0           1.0   \n",
       "997            0.0              0.0              1.0           1.0   \n",
       "998            1.0              0.0              1.0           0.0   \n",
       "999            0.0              0.0              1.0           1.0   \n",
       "\n",
       "     housing_A153  job_A172  job_A173  job_A174  telephone_A192  \\\n",
       "0             0.0       0.0       1.0       0.0             1.0   \n",
       "1             0.0       0.0       1.0       0.0             0.0   \n",
       "2             0.0       1.0       0.0       0.0             0.0   \n",
       "3             1.0       0.0       1.0       0.0             0.0   \n",
       "4             1.0       0.0       1.0       0.0             0.0   \n",
       "..            ...       ...       ...       ...             ...   \n",
       "995           0.0       1.0       0.0       0.0             0.0   \n",
       "996           0.0       0.0       0.0       1.0             1.0   \n",
       "997           0.0       0.0       1.0       0.0             0.0   \n",
       "998           1.0       0.0       1.0       0.0             1.0   \n",
       "999           0.0       0.0       1.0       0.0             0.0   \n",
       "\n",
       "     foreign_worker_A202  \n",
       "0                    0.0  \n",
       "1                    0.0  \n",
       "2                    0.0  \n",
       "3                    0.0  \n",
       "4                    0.0  \n",
       "..                   ...  \n",
       "995                  0.0  \n",
       "996                  0.0  \n",
       "997                  0.0  \n",
       "998                  0.0  \n",
       "999                  0.0  \n",
       "\n",
       "[1000 rows x 48 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize our dataframe\n",
    "# run this normalized df in MLPClassifier\n",
    "# use min max scalar to normalize data\n",
    "\n",
    "x = credit_df_complete.values\n",
    "MinMax = preprocessing.MinMaxScaler()\n",
    "norml = MinMax.fit_transform(x)\n",
    "df_norm = pd.DataFrame(norml)\n",
    "df_norm.columns = credit_df_complete.columns\n",
    "X = df_norm    # pandas dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state = 42)\n",
    "\n",
    "# multi-layer perceptron classifier\n",
    "mlp = MLPClassifier(random_state=42, hidden_layer_sizes=120, max_iter=700)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print('acc for training data: {:.3f}'.format(mlp.score(X_train, y_train)))\n",
    "print('acc for test data: {:.3f}'.format(mlp.score(X_test, y_test)))\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize data and use MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc for training data: 1.000\n",
      "acc for test data: 0.810\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>amount</th>\n",
       "      <th>inst_rate</th>\n",
       "      <th>residing_since</th>\n",
       "      <th>age</th>\n",
       "      <th>num_credits</th>\n",
       "      <th>dependents</th>\n",
       "      <th>checkin_acc_A12</th>\n",
       "      <th>checkin_acc_A13</th>\n",
       "      <th>checkin_acc_A14</th>\n",
       "      <th>...</th>\n",
       "      <th>property_A124</th>\n",
       "      <th>inst_plans_A142</th>\n",
       "      <th>inst_plans_A143</th>\n",
       "      <th>housing_A152</th>\n",
       "      <th>housing_A153</th>\n",
       "      <th>job_A172</th>\n",
       "      <th>job_A173</th>\n",
       "      <th>job_A174</th>\n",
       "      <th>telephone_A192</th>\n",
       "      <th>foreign_worker_A202</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.236478</td>\n",
       "      <td>-0.745131</td>\n",
       "      <td>0.918477</td>\n",
       "      <td>1.046987</td>\n",
       "      <td>2.766456</td>\n",
       "      <td>1.027079</td>\n",
       "      <td>-0.428290</td>\n",
       "      <td>-0.606621</td>\n",
       "      <td>-0.259299</td>\n",
       "      <td>-0.806328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426653</td>\n",
       "      <td>-0.222076</td>\n",
       "      <td>0.478018</td>\n",
       "      <td>0.634448</td>\n",
       "      <td>-0.347960</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.766356</td>\n",
       "      <td>-0.416784</td>\n",
       "      <td>1.214598</td>\n",
       "      <td>-0.196014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.248194</td>\n",
       "      <td>0.949817</td>\n",
       "      <td>-0.870183</td>\n",
       "      <td>-0.765977</td>\n",
       "      <td>-1.191404</td>\n",
       "      <td>-0.704926</td>\n",
       "      <td>-0.428290</td>\n",
       "      <td>1.648476</td>\n",
       "      <td>-0.259299</td>\n",
       "      <td>-0.806328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426653</td>\n",
       "      <td>-0.222076</td>\n",
       "      <td>0.478018</td>\n",
       "      <td>0.634448</td>\n",
       "      <td>-0.347960</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.766356</td>\n",
       "      <td>-0.416784</td>\n",
       "      <td>-0.823318</td>\n",
       "      <td>-0.196014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.738668</td>\n",
       "      <td>-0.416562</td>\n",
       "      <td>-0.870183</td>\n",
       "      <td>0.140505</td>\n",
       "      <td>1.183312</td>\n",
       "      <td>-0.704926</td>\n",
       "      <td>2.334869</td>\n",
       "      <td>-0.606621</td>\n",
       "      <td>-0.259299</td>\n",
       "      <td>1.240190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426653</td>\n",
       "      <td>-0.222076</td>\n",
       "      <td>0.478018</td>\n",
       "      <td>0.634448</td>\n",
       "      <td>-0.347960</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.304877</td>\n",
       "      <td>-0.416784</td>\n",
       "      <td>-0.823318</td>\n",
       "      <td>-0.196014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.750384</td>\n",
       "      <td>1.634247</td>\n",
       "      <td>-0.870183</td>\n",
       "      <td>1.046987</td>\n",
       "      <td>0.831502</td>\n",
       "      <td>-0.704926</td>\n",
       "      <td>2.334869</td>\n",
       "      <td>-0.606621</td>\n",
       "      <td>-0.259299</td>\n",
       "      <td>-0.806328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426653</td>\n",
       "      <td>-0.222076</td>\n",
       "      <td>0.478018</td>\n",
       "      <td>-1.576173</td>\n",
       "      <td>2.873893</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.766356</td>\n",
       "      <td>-0.416784</td>\n",
       "      <td>-0.823318</td>\n",
       "      <td>-0.196014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.256953</td>\n",
       "      <td>0.566664</td>\n",
       "      <td>0.024147</td>\n",
       "      <td>1.046987</td>\n",
       "      <td>1.535122</td>\n",
       "      <td>1.027079</td>\n",
       "      <td>2.334869</td>\n",
       "      <td>-0.606621</td>\n",
       "      <td>-0.259299</td>\n",
       "      <td>-0.806328</td>\n",
       "      <td>...</td>\n",
       "      <td>2.343823</td>\n",
       "      <td>-0.222076</td>\n",
       "      <td>0.478018</td>\n",
       "      <td>-1.576173</td>\n",
       "      <td>2.873893</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.766356</td>\n",
       "      <td>-0.416784</td>\n",
       "      <td>-0.823318</td>\n",
       "      <td>-0.196014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.738668</td>\n",
       "      <td>-0.544162</td>\n",
       "      <td>0.024147</td>\n",
       "      <td>1.046987</td>\n",
       "      <td>-0.399832</td>\n",
       "      <td>-0.704926</td>\n",
       "      <td>-0.428290</td>\n",
       "      <td>-0.606621</td>\n",
       "      <td>-0.259299</td>\n",
       "      <td>1.240190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426653</td>\n",
       "      <td>-0.222076</td>\n",
       "      <td>0.478018</td>\n",
       "      <td>0.634448</td>\n",
       "      <td>-0.347960</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.304877</td>\n",
       "      <td>-0.416784</td>\n",
       "      <td>-0.823318</td>\n",
       "      <td>-0.196014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.754763</td>\n",
       "      <td>0.207612</td>\n",
       "      <td>0.918477</td>\n",
       "      <td>1.046987</td>\n",
       "      <td>0.391740</td>\n",
       "      <td>-0.704926</td>\n",
       "      <td>-0.428290</td>\n",
       "      <td>-0.606621</td>\n",
       "      <td>-0.259299</td>\n",
       "      <td>-0.806328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426653</td>\n",
       "      <td>-0.222076</td>\n",
       "      <td>0.478018</td>\n",
       "      <td>0.634448</td>\n",
       "      <td>-0.347960</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.304877</td>\n",
       "      <td>2.399324</td>\n",
       "      <td>1.214598</td>\n",
       "      <td>-0.196014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.738668</td>\n",
       "      <td>-0.874503</td>\n",
       "      <td>0.918477</td>\n",
       "      <td>1.046987</td>\n",
       "      <td>0.215835</td>\n",
       "      <td>-0.704926</td>\n",
       "      <td>-0.428290</td>\n",
       "      <td>-0.606621</td>\n",
       "      <td>-0.259299</td>\n",
       "      <td>1.240190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426653</td>\n",
       "      <td>-0.222076</td>\n",
       "      <td>0.478018</td>\n",
       "      <td>0.634448</td>\n",
       "      <td>-0.347960</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.766356</td>\n",
       "      <td>-0.416784</td>\n",
       "      <td>-0.823318</td>\n",
       "      <td>-0.196014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.999289</td>\n",
       "      <td>-0.505528</td>\n",
       "      <td>0.918477</td>\n",
       "      <td>1.046987</td>\n",
       "      <td>-1.103451</td>\n",
       "      <td>-0.704926</td>\n",
       "      <td>-0.428290</td>\n",
       "      <td>-0.606621</td>\n",
       "      <td>-0.259299</td>\n",
       "      <td>-0.806328</td>\n",
       "      <td>...</td>\n",
       "      <td>2.343823</td>\n",
       "      <td>-0.222076</td>\n",
       "      <td>0.478018</td>\n",
       "      <td>-1.576173</td>\n",
       "      <td>2.873893</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.766356</td>\n",
       "      <td>-0.416784</td>\n",
       "      <td>1.214598</td>\n",
       "      <td>-0.196014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1.999289</td>\n",
       "      <td>0.462457</td>\n",
       "      <td>0.024147</td>\n",
       "      <td>1.046987</td>\n",
       "      <td>-0.751642</td>\n",
       "      <td>-0.704926</td>\n",
       "      <td>-0.428290</td>\n",
       "      <td>1.648476</td>\n",
       "      <td>-0.259299</td>\n",
       "      <td>-0.806328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426653</td>\n",
       "      <td>-0.222076</td>\n",
       "      <td>0.478018</td>\n",
       "      <td>0.634448</td>\n",
       "      <td>-0.347960</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.766356</td>\n",
       "      <td>-0.416784</td>\n",
       "      <td>-0.823318</td>\n",
       "      <td>-0.196014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     duration    amount  inst_rate  residing_since       age  num_credits  \\\n",
       "0   -1.236478 -0.745131   0.918477        1.046987  2.766456     1.027079   \n",
       "1    2.248194  0.949817  -0.870183       -0.765977 -1.191404    -0.704926   \n",
       "2   -0.738668 -0.416562  -0.870183        0.140505  1.183312    -0.704926   \n",
       "3    1.750384  1.634247  -0.870183        1.046987  0.831502    -0.704926   \n",
       "4    0.256953  0.566664   0.024147        1.046987  1.535122     1.027079   \n",
       "..        ...       ...        ...             ...       ...          ...   \n",
       "995 -0.738668 -0.544162   0.024147        1.046987 -0.399832    -0.704926   \n",
       "996  0.754763  0.207612   0.918477        1.046987  0.391740    -0.704926   \n",
       "997 -0.738668 -0.874503   0.918477        1.046987  0.215835    -0.704926   \n",
       "998  1.999289 -0.505528   0.918477        1.046987 -1.103451    -0.704926   \n",
       "999  1.999289  0.462457   0.024147        1.046987 -0.751642    -0.704926   \n",
       "\n",
       "     dependents  checkin_acc_A12  checkin_acc_A13  checkin_acc_A14  ...  \\\n",
       "0     -0.428290        -0.606621        -0.259299        -0.806328  ...   \n",
       "1     -0.428290         1.648476        -0.259299        -0.806328  ...   \n",
       "2      2.334869        -0.606621        -0.259299         1.240190  ...   \n",
       "3      2.334869        -0.606621        -0.259299        -0.806328  ...   \n",
       "4      2.334869        -0.606621        -0.259299        -0.806328  ...   \n",
       "..          ...              ...              ...              ...  ...   \n",
       "995   -0.428290        -0.606621        -0.259299         1.240190  ...   \n",
       "996   -0.428290        -0.606621        -0.259299        -0.806328  ...   \n",
       "997   -0.428290        -0.606621        -0.259299         1.240190  ...   \n",
       "998   -0.428290        -0.606621        -0.259299        -0.806328  ...   \n",
       "999   -0.428290         1.648476        -0.259299        -0.806328  ...   \n",
       "\n",
       "     property_A124  inst_plans_A142  inst_plans_A143  housing_A152  \\\n",
       "0        -0.426653        -0.222076         0.478018      0.634448   \n",
       "1        -0.426653        -0.222076         0.478018      0.634448   \n",
       "2        -0.426653        -0.222076         0.478018      0.634448   \n",
       "3        -0.426653        -0.222076         0.478018     -1.576173   \n",
       "4         2.343823        -0.222076         0.478018     -1.576173   \n",
       "..             ...              ...              ...           ...   \n",
       "995      -0.426653        -0.222076         0.478018      0.634448   \n",
       "996      -0.426653        -0.222076         0.478018      0.634448   \n",
       "997      -0.426653        -0.222076         0.478018      0.634448   \n",
       "998       2.343823        -0.222076         0.478018     -1.576173   \n",
       "999      -0.426653        -0.222076         0.478018      0.634448   \n",
       "\n",
       "     housing_A153  job_A172  job_A173  job_A174  telephone_A192  \\\n",
       "0       -0.347960      -0.5  0.766356 -0.416784        1.214598   \n",
       "1       -0.347960      -0.5  0.766356 -0.416784       -0.823318   \n",
       "2       -0.347960       2.0 -1.304877 -0.416784       -0.823318   \n",
       "3        2.873893      -0.5  0.766356 -0.416784       -0.823318   \n",
       "4        2.873893      -0.5  0.766356 -0.416784       -0.823318   \n",
       "..            ...       ...       ...       ...             ...   \n",
       "995     -0.347960       2.0 -1.304877 -0.416784       -0.823318   \n",
       "996     -0.347960      -0.5 -1.304877  2.399324        1.214598   \n",
       "997     -0.347960      -0.5  0.766356 -0.416784       -0.823318   \n",
       "998      2.873893      -0.5  0.766356 -0.416784        1.214598   \n",
       "999     -0.347960      -0.5  0.766356 -0.416784       -0.823318   \n",
       "\n",
       "     foreign_worker_A202  \n",
       "0              -0.196014  \n",
       "1              -0.196014  \n",
       "2              -0.196014  \n",
       "3              -0.196014  \n",
       "4              -0.196014  \n",
       "..                   ...  \n",
       "995            -0.196014  \n",
       "996            -0.196014  \n",
       "997            -0.196014  \n",
       "998            -0.196014  \n",
       "999            -0.196014  \n",
       "\n",
       "[1000 rows x 48 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardize our data\n",
    "# run this in our MLPClassifier\n",
    "credit_df_complete = pd.get_dummies( credit_df[X_features], drop_first = True )\n",
    "scaler = preprocessing.StandardScaler()  # from sklearn import preprocessing is used instead of importing StandardScalar()\n",
    "scaler.fit(credit_df_complete)\n",
    "df_std= pd.DataFrame(scaler.transform(credit_df_complete), columns=credit_df_complete.columns)\n",
    "\n",
    "X = df_std    # pandas dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.1, random_state = 42)\n",
    "\n",
    "# print(credit_df_complete.shape)\n",
    "\n",
    "# multi-layer perceptron classifier\n",
    "mlp = MLPClassifier(random_state=42, hidden_layer_sizes=120, max_iter=700)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "print('acc for training data: {:.3f}'.format(mlp.score(X_train, y_train)))\n",
    "print('acc for test data: {:.3f}'.format(mlp.score(X_test, y_test)))\n",
    "df_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN & Setting up Confusion Matrix for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.patches.Wedge at 0x11f9ede50>,\n",
       "  <matplotlib.patches.Wedge at 0x11f9ed9a0>,\n",
       "  <matplotlib.patches.Wedge at 0x11f9eda30>,\n",
       "  <matplotlib.patches.Wedge at 0x11f9dc070>],\n",
       " [Text(0.9715165231687864, 0.5159027478217508, 'Accuracy'),\n",
       "  Text(-0.36086748310962385, 1.0391220619513983, 'Recall(sensitivity)'),\n",
       "  Text(-0.9469476059719615, -0.5597233526877105, 'Precision'),\n",
       "  Text(0.6982773088178625, -0.8499463512422909, 'FScore')])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# implements the confusion matrix to return some metrics based on predictions and actual values based \n",
    "# on the KNNNeighborsClassifier method\n",
    "def evaluateBinaryClassification(predictions, actuals):\n",
    "    contigency = pd.crosstab(actuals,predictions)\n",
    "    TP = contigency[0][1]\n",
    "    TN = contigency[1][1]\n",
    "    FP = contigency[0][1]\n",
    "    FN = contigency[1][0]\n",
    "    n = contigency.sum().sum()\n",
    "\n",
    "    Acuracy = (TP + TN)/n   # the percentage of corrections we got right over all predictions\n",
    "    Recall = TP/(TP+FN) # the percentage of positive that were predicted as positive (sensitivity)\n",
    "    Precision = TP/(TP+FP) # what predictions came up positive out of all predictions\n",
    "    FScore = 2*Recall*Precision/(Recall+Precision)  # the harmonic score of precision\n",
    "    \n",
    "    return Acuracy, Recall, Precision, FScore\n",
    "\n",
    "    \n",
    "select_features=df[df.importance>=0.03].feature\n",
    "\n",
    "# knn\n",
    "knn = KNeighborsClassifier(n_neighbors=3, weights='uniform').fit(X_train[select_features], y_train)\n",
    "y_predict_knn = knn.predict(X_test[select_features])\n",
    "pd.crosstab(y_test, y_predict_knn)\n",
    "binaryClassificationMetrics = evaluateBinaryClassification(y_predict_knn, y_test)\n",
    "\n",
    "\n",
    "# display binary classification metrics for KNN\n",
    "pieLabels = [\"Accuracy\", \"Recall(sensitivity)\", \"Precision\", \"FScore\"]\n",
    "plt.pie(binaryClassificationMetrics, labels = pieLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y_test,y_pred)\n",
    "print('Accuracy :',score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>1</td>\n",
       "      <td>0.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>0</td>\n",
       "      <td>0.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>0</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0</td>\n",
       "      <td>0.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>0</td>\n",
       "      <td>0.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>0.275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>0.925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>1</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted\n",
       "521       1      0.215\n",
       "737       0      0.283\n",
       "740       0      0.624\n",
       "660       0      0.497\n",
       "411       0      0.007\n",
       "..      ...        ...\n",
       "436       0      0.387\n",
       "764       0      0.034\n",
       "88        0      0.275\n",
       "63        1      0.925\n",
       "826       1      0.292\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "df = pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute confusion matrix for credit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    # plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[62  9]\n",
      " [10 19]]\n",
      "Normalized confusion matrix\n",
      "[[0.87 0.13]\n",
      " [0.34 0.66]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names=credit_df.target_names\n",
    "y_pred= mlp.predict(X_test)\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary \n",
    "### Results from regular df\n",
    "acc for training data: 0.583\n",
    "acc for test data: 0.610\n",
    "\n",
    "### Results for normalized df\n",
    "acc for training data: 1.000\n",
    "acc for test data: 0.790\n",
    "\n",
    "### Results for standardized df\n",
    "acc for training data: 1.000\n",
    "acc for test data: 0.810\n",
    "\n",
    "### Logistic Regression results\n",
    "Accuracy : 0.8\n",
    "\n",
    "### Results of random forest regression\n",
    "```c++\n",
    "\n",
    "Actual\tPredicted\n",
    "521\t1\t0.215\n",
    "737\t0\t0.283\n",
    "740\t0\t0.624\n",
    "660\t0\t0.497\n",
    "411\t0\t0.007\n",
    "...\t...\t...\n",
    "436\t0\t0.387\n",
    "764\t0\t0.034\n",
    "88\t0\t0.275\n",
    "63\t1\t0.925\n",
    "826\t1\t0.292\n",
    "\n",
    "```\n",
    "\n",
    "# Conclusion\n",
    "The most accurate model seems to be using MLPClassifier on standardized data.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
